{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import DatasetGenerator, RelevancyEvaluator\n",
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    "    Response,\n",
    ")\n",
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "# Set your OpenAI API key here\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(organization=\"transiis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/aether-physics/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --user-agent \"Mozilla\" \"https://www.dropbox.com/scl/fi/mxhuptzzdv43d6fdfz6zn/A-History-of-the-Theories-of-Aether-and-Electricity-by-Edmund-Taylor-Whittaker-1910.pdf?rlkey=s32cuzxqnfrdyrgc462tek0o9&dl=1\" -O \"data/aether-physics/A-History-of-the-Theories-of-Aether-and-Electricity-by-Edmund-Taylor-Whittaker-1910.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\"data/aether-physics/\")\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade llama_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.evaluation import DatasetGenerator\n",
    "import asyncio\n",
    "\n",
    "\n",
    "# Use the existing event loop instead of asyncio.run()\n",
    "loop = asyncio.get_event_loop()\n",
    "eval_questions = loop.run_until_complete(data_generator.generate_questions_from_nodes())\n",
    "\n",
    "\n",
    "# Build service context\n",
    "llm = OpenAI(model=\"gpt-4\", temperature=0.0)\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "\n",
    "# Build documents\n",
    "reader = SimpleDirectoryReader(\"data/aether-physics/\")\n",
    "\n",
    "# Define generator, generate questions\n",
    "data_generator = DatasetGenerator.from_documents(documents, service_context=service_context)\n",
    "\n",
    "eval_questions = data_generator.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-4\n",
    "gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_gpt4 = RelevancyEvaluator(service_context=service_context_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector index\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents, service_context=service_context_gpt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define jupyter display function\n",
    "def display_eval_df(query: str, response: Response, eval_result: str) -> None:\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Query\": query,\n",
    "            \"Response\": str(response),\n",
    "            \"Source\": (\n",
    "                response.source_nodes[0].node.get_content()[:1000] + \"...\"\n",
    "            ),\n",
    "            \"Evaluation Result\": eval_result,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "    eval_df = eval_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"600px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        },\n",
    "        subset=[\"Response\", \"Source\"]\n",
    "    )\n",
    "    display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine()\n",
    "response_vector = query_engine.query(eval_questions[1])\n",
    "eval_result = evaluator_gpt4.evaluate_response(\n",
    "    query=eval_questions[1], response=response_vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_eval_df(eval_questions[1], response_vector, eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
